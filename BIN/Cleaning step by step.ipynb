{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20142168",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OneDrive - Nanyang Technological University/TFIPGA/Thomson Capstone/scotch_review2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOneDrive - Nanyang Technological University/TFIPGA/Thomson Capstone/scotch_review2020.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OneDrive - Nanyang Technological University/TFIPGA/Thomson Capstone/scotch_review2020.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "df2 = pd.read_csv(r\"OneDrive - Nanyang Technological University/TFIPGA/Thomson Capstone/scotch_review2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fe3617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mapply(has_review, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Assuming you have your DataFrame named 'df'\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m drop_non_review_rows(df)\n\u001b[0;32m     22\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m\"\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#filtered_df = filtered_df.iloc[:, [0, -1]]  # Select desired columns by position\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save the filtered DataFrame to a new CSV file (optional)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def drop_non_review_rows(df, review_term=\"Review #\"):\n",
    "    \"\"\"Drops rows where the first column does not contain the specified review term (case-insensitive).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        review_term (str, optional): The term to search for (defaults to \"review\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with non-review rows removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def has_review(row):\n",
    "        # Check if the first column (Title) contains the review term (case-insensitive)\n",
    "        return review_term.lower() in str(row['Title']).lower()\n",
    "\n",
    "    return df.loc[df.apply(has_review, axis=1)]\n",
    "\n",
    "\n",
    "# Assuming you have your DataFrame named 'df'\n",
    "filtered_df = drop_non_review_rows(df)\n",
    "\n",
    "filtered_df = filtered_df.drop([\"URL\",\"Content\"],axis=1)\n",
    "#filtered_df = filtered_df.iloc[:, [0, -1]]  # Select desired columns by position\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file (optional)\n",
    "filtered_df.to_csv('filtered_reviews.csv', index=False)\n",
    "\n",
    "print(filtered_df)\n",
    "print(\"Data cleaning completed! Filtered data saved to filtered_reviews.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b987a7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#df_drop_columns = pd.read_csv(r\"C:\\Users\\N2397\\OneDrive - Nanyang Technological University\\TFIPGA\\Thomson Capstone\\filtered_reviews_with_TC2.csv\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming your DataFrame is named `df_drop_columns` and the column containing review text is named `Title`\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract the desired part of the title using regular expressions\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview #\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+(?:[:,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.]*)(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Matches \"Review #xxx:\" followed by any character sequence\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(pattern, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Print the DataFrame with the modified title\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "#df_drop_columns = pd.read_csv(r\"C:\\Users\\N2397\\OneDrive - Nanyang Technological University\\TFIPGA\\Thomson Capstone\\filtered_reviews_with_TC2.csv\")\n",
    "\n",
    "# Assuming your DataFrame is named `df_drop_columns` and the column containing review text is named `Title`\n",
    "\n",
    "# Extract the desired part of the title using regular expressions\n",
    "\n",
    "pattern = r\"Review #\\d+(?:[:,\\.]*)(.*)\"  # Matches \"Review #xxx:\" followed by any character sequence\n",
    "\n",
    "\n",
    "filtered_df['Title'] = filtered_df['Title'].str.extract(pattern, expand=True)\n",
    "\n",
    "# Print the DataFrame with the modified title\n",
    "print(filtered_df)\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file (optional)\n",
    "filtered_df.to_csv('filtered_reviews_drop_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3b11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_asterisks(text):\n",
    "  \"\"\"\n",
    "  Removes asterisks (*) from the input text.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to remove asterisks from.\n",
    "\n",
    "  Returns:\n",
    "      str: The text with asterisks removed.\n",
    "  \"\"\"\n",
    "  if pd.isna(text):  # Handle missing values in the \"Comments\" column\n",
    "    return text\n",
    "  else:\n",
    "    return re.sub(r\"\\*\", \"\", text)\n",
    "\n",
    "# Create a new column named \"Cleaned Comments\" with asterisks removed\n",
    "filtered_df[\"Cleaned Comments\"] = filtered_df[\"Comments\"].apply(remove_asterisks)\n",
    "\n",
    "# Print the DataFrame with the new column\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9fed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filtered_df.to_csv('filtered_no_asterisks.csv', index=False)\n",
    "temp_df = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b765eb5d",
   "metadata": {},
   "source": [
    "def extract_tasting_notes(text):\n",
    "  \"\"\"\n",
    "  Extracts tasting notes (Nose, Taste, Finish) from the input text.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to extract tasting notes from.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary containing the extracted tasting notes (Nose, Taste, Finish), or an empty dictionary if no notes are found.\n",
    "  \"\"\"\n",
    "  notes = {}\n",
    "  for part in text.split(\"\\n\\n\"):\n",
    "    # Split by colon (\":\") to get the part name (e.g., Nose) and description\n",
    "    if \":\" in part:\n",
    "      name, description = part.split(\":\", 1)\n",
    "      notes[name.strip()] = description.strip()\n",
    "  return notes\n",
    "\n",
    "# Apply the function, check for empty notes, and create new columns\n",
    "def assign_tasting_notes(row):\n",
    "  notes = extract_tasting_notes(row[\"Cleaned Comments\"])\n",
    "  if notes:  # Check if notes dictionary is not empty\n",
    "    return pd.Series({\"Title\": row.get(\"Title\", \"\"), \"Nose\": notes.get(\"Nose\", \"\"), \"Taste\": notes.get(\"Taste\", \"\"), \"Finish\": notes.get(\"Finish\", \"\")})\n",
    "  else:\n",
    "    return pd.Series({\"Title\": \"\", \"Nose\": \"\", \"Taste\": \"\", \"Finish\": \"\"})  # Return empty series if no notes\n",
    "\n",
    "filtered_df = filtered_df.apply(assign_tasting_notes, axis=1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "filtered_df.to_csv(\"extracted_tasting_notes1.csv\", index=False)\n",
    "\n",
    "# Print confirmation message (optional)\n",
    "print(\"Tasting notes saved to extracted_tasting_notes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42372e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_tasting_notes(text):\n",
    "  \"\"\"\n",
    "  Extracts tasting notes (Nose, Taste, Finish) and score from the input text.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to extract tasting notes and score from.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary containing the extracted tasting notes (Nose, Taste, Finish)\n",
    "            and score (as the number before \"/10\"), or an empty dictionary if no notes are found.\n",
    "  \"\"\"\n",
    "  notes = {}\n",
    "  score_match = re.search(r\"\\d+/\\d+$\", text)  # Regex to find \"x/10\" pattern\n",
    "  if score_match:\n",
    "    score = score_match.group().split(\"/\")[0]  # Extract only the number before \"/10\"\n",
    "    notes[\"Score\"] = score\n",
    "\n",
    "  for part in text.split(\"\\n\"):\n",
    "    # Split by colon (\":\") to get the part name (e.g., Nose) and description\n",
    "    if \":\" in part:\n",
    "      name, description = part.split(\":\", 1)\n",
    "      notes[name.strip()] = description.strip()\n",
    "  return notes\n",
    "\n",
    "# Apply the function, check for empty notes, and create new columns\n",
    "def assign_tasting_notes(row):\n",
    "  notes = extract_tasting_notes(row[\"Cleaned Comments\"])\n",
    "  if notes:  # Check if notes dictionary is not empty\n",
    "    return pd.Series({\"Title\": row.get(\"Title\", \"\"), \"Nose\": notes.get(\"Nose\", \"\"), \"Taste\": notes.get(\"Taste\", \"\"), \"Finish\": notes.get(\"Finish\", \"\"), \"Score\": notes.get(\"Score\", \"\")})\n",
    "  else:\n",
    "    return pd.Series({\"Title\": \"\", \"Nose\": \"\", \"Taste\": \"\", \"Finish\": \"\", \"Score\": \"\"})  # Return empty series if no notes\n",
    "filtered_df = filtered_df.apply(assign_tasting_notes, axis=1)\n",
    "\n",
    "def format_score(score):\n",
    "  \"\"\"\n",
    "  Removes \"/10\" from the score string (if present).\n",
    "\n",
    "  Args:\n",
    "      score (str): The score string (e.g., \"9\").\n",
    "\n",
    "  Returns:\n",
    "      str: The score without \"/10\", or an empty string if no score is found.\n",
    "  \"\"\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "filtered_df.to_csv(\"extracted_tasting_notes.csv\", index=False)\n",
    "\n",
    "# Print confirmation message (optional)\n",
    "print(\"Tasting notes and score saved to extracted_tasting_notes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bf838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_extract_tasting_notes(text):\n",
    "  \"\"\"\n",
    "  Extracts tasting notes (Nose, Taste, Finish) and score from the input text.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to extract tasting notes and score from.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary containing the extracted tasting notes (Nose, Taste, Finish)\n",
    "            and score (as the number before \"/10\"), or an empty dictionary if no notes are found.\n",
    "  \"\"\"\n",
    "  notes = {}\n",
    "  score_match = re.search(r\"\\d+/\\d+$\", text)  # Regex to find \"x/10\" pattern\n",
    "  print(score_match)\n",
    "  if score_match:\n",
    "    score = score_match.group().split(\"/\")[0]  # Extract only the number before \"/10\"\n",
    "    notes[\"Score\"] = score\n",
    "\n",
    "  for part in text.split(\"\\n\"):\n",
    "    # Split by colon (\":\") to get the part name (e.g., Nose) and description\n",
    "    if \":\" in part:\n",
    "      name, description = part.split(\":\", 1)\n",
    "      notes[name.strip()] = description.strip()\n",
    "  return notes\n",
    "\n",
    "new_extract_tasting_notes(temp_df[\"Cleaned Comments\"][425])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586d9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check if a value is a number\n",
    "def is_number(value):\n",
    "    return isinstance(value, (int, float))\n",
    "\n",
    "# Function to extract the first number from a string\n",
    "def extract_first_number(text):\n",
    "    numbers = re.findall(r'\\d+', str(text))\n",
    "    return int(numbers[0]) if numbers else None\n",
    "\n",
    "# Apply the transformation\n",
    "filtered_df['Score'] = filtered_df['Score'].apply(lambda x: extract_first_number(x) if not is_number(x) else x)\n",
    "filtered_df.to_csv('clean_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405f33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e8d83-1e53-427a-bb37-715502e059b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the rows with null values\n",
    "null_rows = filtered_df[filtered_df.isnull().any(axis=1)]\n",
    "\n",
    "num_null_rows = null_rows.shape[0]\n",
    "\n",
    "# Print the number of null rows\n",
    "print(f\"Number of null rows: {num_null_rows}\")\n",
    "\n",
    "# Print the null rows\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae989205-8b35-4e57-9892-bebad30b8760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4194ae-2daa-4e74-bc03-f47bede122bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
