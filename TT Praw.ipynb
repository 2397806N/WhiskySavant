{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3106ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import csv\n",
    "import time\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"zyWV31wzwbRJpdk1CMn7qQ\",\n",
    "    client_secret=\"9ytU5NETlMvpp6KuUmqaScdOe9aEXA\",\n",
    "    user_agent=\"Whisky Capstone by u/2397806N \",\n",
    "    username=\"2397806N\",\n",
    "    password=\"7u8i9o0p\",\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b366eb1",
   "metadata": {},
   "source": [
    "#praw whole subreddit base on \"review\" + \"tasting notes\"\n",
    "\n",
    "# Open the subreddit\n",
    "subreddit = reddit.subreddit(\"whiskey\")\n",
    "\n",
    "# Search terms (adjust as needed)\n",
    "search_terms = [\"review\", \"tasting notes\"]\n",
    "\n",
    "# Create the CSV file\n",
    "with open(\"whiskey_reviews_upto_1000.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Title\", \"Content\", \"Comments\"])\n",
    "\n",
    "    # Retrieve posts using search (limited to 1000)\n",
    "    reviews = subreddit.search(\" \".join(search_terms), sort=\"new\", limit=1000)\n",
    "\n",
    "    # Extract data from each review post\n",
    "    for submission in reviews:\n",
    "        title = submission.title\n",
    "        content = submission.selftext\n",
    "\n",
    "        # Collect comments (replace with max comments to retrieve)\n",
    "        comments = []\n",
    "        submission.comments.replace_more(limit=None)  # Get all comments (cautious of throttling)\n",
    "        for comment in submission.comments.list():\n",
    "            comments.append(comment.body)\n",
    "\n",
    "        # Combine comments into a single string\n",
    "        comments_str = \"\\n\".join(comments)\n",
    "\n",
    "        # Write data to CSV\n",
    "        writer.writerow([title, content, comments_str])\n",
    "\n",
    "print(\"Extracted up to 1000 whisky reviews saved to whisky_reviews_upto_1000.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_posts(reddit, subreddit_name, target_username, csv_filename):\n",
    "    \"\"\"Retrieves all posts by a user in a subreddit and saves them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        reddit (praw.Reddit): The PRAW Reddit instance.\n",
    "        subreddit_name (str): The name of the subreddit (e.g., \"whisky\").\n",
    "        target_username (str): The username of the target user.\n",
    "        csv_filename (str): The filename for the CSV file to save posts.\n",
    "    \"\"\"\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    target_user = reddit.redditor(target_username)\n",
    "\n",
    "    posts = []\n",
    "\n",
    "    with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Title\", \"Content\", \"URL\", \"Comments\"])\n",
    "\n",
    "        for submission in target_user.submissions.new(limit=None):\n",
    "            # Extract data and write to CSV\n",
    "            title = submission.title\n",
    "            content = submission.selftext\n",
    "            url = submission.url  # Include post URL\n",
    "\n",
    "            # Collect comments (replace with max comments to retrieve)\n",
    "            comments = []\n",
    "            submission.comments.replace_more(limit=None)  # Get all comments (cautious of throttling)\n",
    "            for comment in submission.comments.list():\n",
    "                comments.append(comment.body)\n",
    "\n",
    "            # Combine comments into a single string\n",
    "            comments_str = \"\\n\".join(comments)\n",
    "\n",
    "            writer.writerow([title, content, url, comments_str])\n",
    "            \n",
    "            # Sleep for the specified delay\n",
    "            time.sleep(1)\n",
    "\n",
    "    if posts:\n",
    "        print(f\"Found {len(posts)} posts by {target_username} in r/{subreddit_name} and saved to {csv_filename}\")\n",
    "    else:\n",
    "        print(f\"No posts found for user {target_username} in r/{subreddit_name}\")\n",
    "\n",
    "\n",
    "# Usernames and subreddits\n",
    "usernames = [\"adunitbx\", \"buckydean\", \"Coirebreacan\",\"deppsdoeswhisky\", \"kaedoge\"]\n",
    "subreddits = [\"whisky\", \"whiskey\", \"scotch\"]\n",
    "\n",
    "# Loop through users and subreddits\n",
    "for username, subreddit in zip(usernames, subreddits):\n",
    "    csv_filename = f\"{username}_{subreddit}_posts.csv\"\n",
    "    get_user_posts(reddit, subreddit, username, csv_filename)\n",
    "\n",
    "print(\"Finished retrieving posts for all users and subreddits.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c3c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
